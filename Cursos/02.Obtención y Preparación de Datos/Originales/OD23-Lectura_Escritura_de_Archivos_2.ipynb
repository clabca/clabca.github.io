{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pyBWr_NEKgCN"},"source":["# **Obtención y preparación de datos**\n","\n","# OD23. Lectura y escritura de archivos con Pandas 2\n","<img src=\"https://drive.google.com/uc?export=view&id=1Igtn9UXg6NGeRWsqh4hefQUjV0hmzlBv\" width=\"100\" align=\"left\" title=\"Runa-perth\">\n","<br clear=\"left\">\n","\n","##<font color='red'>__Contenido opcional__</font>"]},{"cell_type":"markdown","source":["## <font color='blue'>**Datos de trabajo**</font>\n","\n","Para nuestro aprendizaje, utilizaremos la siguiente data, la cual contiene lo siguiente:\n","* __Pais__: Corresponde al nombre del país. Las etiquetas de fila para el conjunto de datos son los códigos de país de tres letras definidos en ISO 3166-1. La etiqueta de la columna para el conjunto de datos es _PAIS_.\n","\n","* __Población__: La población se expresa en millones. La etiqueta de columna para el conjunto de datos es _POB_.\n","\n","* __Área:__ El área se expresa en miles de kilómetros cuadrados. La etiqueta de la columna para el conjunto de datos es _AREA_.\n","\n","* __Productom Interno Bruto__: El producto interno bruto se expresa en millones de dólares estadounidenses, según los datos de las Naciones Unidas para 2017.  La etiqueta de columna para el conjunto de datos es _PIB_.\n","\n","* __Continente__: El continente es África, Asia, Oceanía, Europa, América. La etiqueta de columna para el conjunto de datos es _CONT_.\n","\n","* __Independencia__: El día de la independencia es una fecha que conmemora la independencia de una nación. Las fechas se muestran en formato ISO 8601. Los primeros cuatro dígitos representan el año, los siguientes dos números son el mes y los dos últimos son para el día del mes. La etiqueta de la columna para el conjunto de datos es _IND_.\n","\n","* __OCDE__: Si el país es miembro o no de la _OCDE_."],"metadata":{"id":"ARapBmhVtuod"}},{"cell_type":"code","source":["# Organizamos la data en un diccionario\n","\n","data = {\n","    'CHN': {'PAIS': 'China', 'POB': 1_398.72, 'AREA': 9_596.96,\n","            'PGB': 12_234.78, 'CONT': 'Asia', 'OCDE': 'No'},\n","    'IND': {'PAIS': 'India', 'POB': 1_351.16, 'AREA': 3_287.26,\n","            'PGB': 2_575.67, 'CONT': 'Asia', 'IND': '1947-08-15', 'OCDE': 'No'},\n","    'USA': {'PAIS': 'US', 'POB': 329.74, 'AREA': 9_833.52,\n","            'PGB': 19_485.39, 'CONT': 'America','IND': '1776-07-04', 'OCDE': 'Si'},\n","    'IDN': {'PAIS': 'Indonesia', 'POB': 268.07, 'AREA': 1_910.93,\n","            'PGB': 1_015.54, 'CONT': 'Asia', 'IND': '1945-08-17', 'OCDE': 'No'},\n","    'BRA': {'PAIS': 'Brasil', 'POB': 210.32, 'AREA': 8_515.77,\n","            'PGB': 2_055.51, 'CONT': 'America', 'IND': '1822-09-07', 'OCDE': 'No'},\n","    'PAK': {'PAIS': 'Pakistan', 'POB': 205.71, 'AREA': 881.91,\n","            'PGB': 302.14, 'CONT': 'Asia', 'IND': '1947-08-14', 'OCDE': 'No'},\n","    'NGA': {'PAIS': 'Nigeria', 'POB': 200.96, 'AREA': 923.77,\n","            'PGB': 375.77, 'CONT': 'Africa', 'IND': '1960-10-01', 'OCDE': 'No'},\n","    'BGD': {'PAIS': 'Bangladesh', 'POB': 167.09, 'AREA': 147.57,\n","            'PGB': 245.63, 'CONT': 'Asia', 'IND': '1971-03-26', 'OCDE': 'No'},\n","    'RUS': {'PAIS': 'Rusia', 'POB': 146.79, 'AREA': 17_098.25,\n","            'PGB': 1_530.75, 'IND': '1992-06-12', 'OCDE': 'No'},\n","    'MEX': {'PAIS': 'Mexico', 'POB': 126.58, 'AREA': 1_964.38,\n","            'PGB': 1_158.23, 'CONT': 'America', 'IND': '1810-09-16', 'OCDE': 'Si'},\n","    'JPN': {'PAIS': 'Japon', 'POB': 126.22, 'AREA': 377.97,\n","            'PGB': 4_872.42, 'CONT': 'Asia', 'OCDE': 'Si'},\n","    'DEU': {'PAIS': 'Alemania', 'POB': 83.02, 'AREA': 357.11,\n","            'PGB': 3_693.20, 'CONT': 'Europe', 'OCDE': 'Si'},\n","    'FRA': {'PAIS': 'Francia', 'POB': 67.02, 'AREA': 640.68,\n","            'PGB': 2_582.49, 'CONT': 'Europe', 'IND': '1789-07-14', 'OCDE': 'Si'},\n","    'GBR': {'PAIS': 'UK', 'POB': 66.44, 'AREA': 242.50,\n","            'PGB': 2_631.23, 'CONT': 'Europe', 'OCDE': 'Si'},\n","    'ITA': {'PAIS': 'Italia', 'POB': 60.36, 'AREA': 301.34,\n","            'PGB': 1_943.84, 'CONT': 'Europe', 'OCDE': 'Si'},\n","    'ARG': {'PAIS': 'Argentina', 'POB': 44.94, 'AREA': 2_780.40,\n","            'PGB': 637.49, 'CONT': 'America', 'IND': '1816-07-09', 'OCDE': 'No'},\n","    'DZA': {'PAIS': 'Algeria', 'POB': 43.38, 'AREA': 2_381.74,\n","            'PGB': 167.56, 'CONT': 'Africa', 'IND': '1962-07-05', 'OCDE': 'No'},\n","    'CAN': {'PAIS': 'Canada', 'POB': 37.59, 'AREA': 9_984.67,\n","            'PGB': 1_647.12, 'CONT': 'America', 'IND': '1867-07-01', 'OCDE': 'Si'},\n","    'AUS': {'PAIS': 'Australia', 'POB': 25.47, 'AREA': 7_692.02,\n","            'PGB': 1_408.68, 'CONT': 'Oceania', 'OCDE': 'Si'},\n","    'CHL': {'PAIS': 'Chile', 'POB': 19.68, 'AREA': 756.10,\n","            'PGB': 317.6, 'CONT': 'America', 'IND': '1818-09-18', 'OCDE': 'Si'},\n","    'KAZ': {'PAIS': 'Kazakistan', 'POB': 18.53, 'AREA': 2_724.90,\n","            'PGB': 159.41, 'CONT': 'Asia', 'IND': '1991-12-16', 'OCDE': 'No'}\n","\n","}\n","\n","columns = ('PAIS', 'POB', 'AREA', 'PGB', 'CONT', 'IND')"],"metadata":{"id":"CRhE_L2awclv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Puede notar que faltan algunos de los datos. Por ejemplo, el continente de Rusia no se especifica porque se extiende por Europa y Asia. También faltan varios días de independencia porque la fuente de datos los omite.\n","\n"],"metadata":{"id":"u-AbVHpcx_G3"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"zA6XDvioybkY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usaremos el constructor `pd.DataFrame` para crear la estructura en Pandas."],"metadata":{"id":"oJFe_WSOyoln"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data)\n","df"],"metadata":{"id":"KgB2ksOLyyuH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos transponer la estructura para que la data quede organizada con el *código_pais* como índice."],"metadata":{"id":"sSUytDCozHdL"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data).T\n","df"],"metadata":{"id":"RlbM5lG7zZg0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nuestra data está lista, vemos como escribir y leer archivos con pandas."],"metadata":{"id":"13OwcdXLznm3"}},{"cell_type":"markdown","source":["## <font color='blue'>**Tipos de Archivos**</font>"],"metadata":{"id":"5_MO-muV6XNr"}},{"cell_type":"markdown","source":["### __Archivos JSON__\n","\n","JSON significa __JavaScript Object Notation__ (notación de objetos de JavaScript). Los archivos JSON son archivos de texto sin formato, fácilmente leíbles por los humanos, que se utilizan para el intercambio de datos. Siguen los estándares ISO/IEC 21778:2017 y ECMA-404 y utilizan la extensión `.json`. Python y Pandas funcionan bien con archivos JSON, ya que la biblioteca `json` de Python ofrece soporte integrado para ellos.\n","\n","Puede guardar los datos de su DataFrame en un archivo JSON con el método `.to_json()`. Comience por crear un objeto DataFrame nuevamente. Use los datos del diccionario que contienen los datos sobre los países y luego aplique `.to_json()`:"],"metadata":{"id":"Vc8A-Yl9ULo7"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data).T\n","df.to_json('data-columns.json')"],"metadata":{"id":"4-zBZM1gU1UR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos cómo se ve en nuestro directorio de trabajo."],"metadata":{"id":"ZsGauWeqU6cW"}},{"cell_type":"code","source":["!cat data-columns.json"],"metadata":{"id":"H_fAj_gSVB0Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["_data-columns.json_ tiene un diccionario con las etiquetas de las columnas como claves y los diccionarios internos correspondientes como valores.\n","\n","Puede crear una estructura de archivo diferente si pasa un argumento `orient`, cuyo valor por defecto es `columns`.  Esta vez lo utilizaremos con `'index'`."],"metadata":{"id":"nnqssl6mVBXZ"}},{"cell_type":"code","source":["df.to_json('data-index.json', orient='index')"],"metadata":{"id":"8ZqLZsGUVj73"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos cómo quedó ahora."],"metadata":{"id":"-EINFTcKVBVC"}},{"cell_type":"code","source":["!cat data-index.json"],"metadata":{"id":"SBy9gfX4WIrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["_data-index.json_ también tiene un diccionario, pero esta vez las etiquetas de las filas son las llaves y los diccionarios internos los valores.\n","\n","Hay pocas opciones más para orientar. Uno de ellos es `records`:"],"metadata":{"id":"FryFkZStVBSN"}},{"cell_type":"code","source":["df.to_json('data-records.json', orient='records')"],"metadata":{"id":"SxuTjAMfWjRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat data-records.json"],"metadata":{"id":"VtgLrrigWp12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["_data-records.json_ contiene una lista con un diccionario para cada fila. Las etiquetas de las filas no están escritas.\n","\n","Puede obtener otra estructura de archivos interesante con `orient='split'`:"],"metadata":{"id":"qexBakVKVBPm"}},{"cell_type":"code","source":["df.to_json('data-split.json', orient='split')"],"metadata":{"id":"RrJePfNmXBgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat data-split.json"],"metadata":{"id":"pykgON0nXECt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["_data-split.json_ contiene un diccionario que contiene las siguientes 3 listas:\n","\n","* Los nombres de las columnas.\n","* Las etiquetas de las filas\n","* Las listas internas (secuencia bidimensional) que contienen valores de datos, con una lista para cada registro.\n","\n","Si no proporciona el valor para el parámetro opcional `path_or_buf` que define la ruta del archivo, `.to_json()` devolverá una cadena JSON en lugar de escribir los resultados en un archivo. Este comportamiento es consistente con el que ya vimos en `.to_csv()`.\n","\n","Hay otros parámetros opcionales que puede utilizar. Por ejemplo, puede establecer `index=False` para renunciar a guardar las etiquetas de las filas. Puede manipular la precisión con `double_precision` y las fechas con `date_forma`t y `date_unit`. Estos dos últimos parámetros son particularmente importantes cuando tiene series de tiempo entre sus datos:"],"metadata":{"id":"xnejWc43VBNA"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data).T\n","df['IND'] = pd.to_datetime(df['IND'])\n","print(df.dtypes, '\\n')\n","df.to_json('data-time.json')"],"metadata":{"id":"caJn-IozXAsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat data-time.json"],"metadata":{"id":"8iWVXkkhYUvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No se ve muy bien porque está al final del archivo. Veamos una forma de visualizar un JSON en forma de árbol."],"metadata":{"id":"2o-7OfkxZ903"}},{"cell_type":"code","source":["import json\n","with open('data-time.json', 'r') as handle:\n","    parsed = json.load(handle)\n","print(json.dumps(parsed, indent=4))"],"metadata":{"id":"vFc8e4_mZsR0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este archivo, _'IND'_  tiene números enteros grandes en lugar de fechas para los días de la independencia. Esto se debe a que el valor predeterminado del parámetro opcional date_format es `epoch` siempre que `orient` no sea `'table'`. Este comportamiento predeterminado expresa las fechas como una época en milisegundos en relación con la medianoche del 1 de enero de 1970.\n","\n","Sin embargo, si pasa `date_format='iso'`, obtendrá las fechas en el formato ISO 8601. Además, `date_unit` decide las unidades de tiempo:"],"metadata":{"id":"3saKcsKdVBK4"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data).T\n","df['IND'] = pd.to_datetime(df['IND'])\n","df.to_json('new-data-time.json', date_format='iso', date_unit='s')"],"metadata":{"id":"8YH_YvAjY2-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('new-data-time.json', 'r') as handle:\n","    # Filtramos solo la llave que queremos verificar ('IND')\n","    print(parsed['IND'])\n","print(json.dumps(parsed['IND'], indent=4))"],"metadata":{"id":"ViW3y8LtaVac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Puede cargar los datos desde un archivo JSON con `read_json()`:"],"metadata":{"id":"cZRXl_YJVBIR"}},{"cell_type":"code","source":["df = pd.read_json('data-index.json',\n","                  orient='index',\n","                  convert_dates=['IND'])"],"metadata":{"id":"CqkGb97jdFsQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El parámetro `convert_dates` tiene un propósito similar al de `parse_dates` cuando lo usa para leer archivos CSV. El parámetro opcional `orient` es muy importante porque especifica cómo Pandas entiende la estructura del archivo.\n","\n","Hay otros parámetros opcionales que también puede usar:\n","\n","* `encodig`, establece la codificación.\n","* `convert_dates` y `keep_default_dates`, para manipular fechas.\n","* `dtype` y `precision_float`, tipos y precisión de los datos.\n","* `numpy=True`, decodificar datos numéricos directamente en matrices NumPy.\n","\n","Tenga en cuenta que puede perder el orden de las filas y las columnas al usar el formato JSON para almacenar sus datos.\n"],"metadata":{"id":"6yIGT_4IVBCj"}},{"cell_type":"markdown","source":["### __Archivos HTML__\n","\n","Un HTML es un archivo de texto sin formato que utiliza lenguaje de marcado de hipertexto para ayudar a los navegadores a representar páginas web. Las extensiones de los archivos HTML son `.html` y `.htm`.\n","\n","El entorno Colab tiene pre-instaladas las biblotecas necesarias para leer y escribir archivos HTML; sin embargo, si no las tuviera instalada, las librerías más comunes con `lxml` o `html5lib`.\n","\n","```python\n","$pip install lxml html5lib\n","````\n","o con Conda\n","```python\n","$ conda install lxml html5lib\n","```"],"metadata":{"id":"EFvSqUYme-z5"}},{"cell_type":"code","source":["df = pd.DataFrame(data=data).T\n","df.to_html('data.html')"],"metadata":{"id":"ms7uqaVTfRih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat data.html"],"metadata":{"id":"ZzdNWF0PgCiI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Este archivo muestra muy bien el contenido de DataFrame. Sin embargo, tenga en cuenta que no ha obtenido una página web completa. Acaba de generar los datos que corresponden a _df_ en formato HTML.\n","\n","`.to_html()` no creará un archivo si no proporciona el parámetro opcional `buf`, que indica el nombre del archivo (búfer) en el cual escribir. Si deja fuera este parámetro, su código devolverá una cadena de forma similar como lo hizo con `.to_csv()` y .`to_json()`.\n","\n","Aquí hay algunos otros parámetros opcionales:\n","\n","* `header` determina si guardar los nombres de las columnas.\n","* `index` determina si guardar las etiquetas de fila.\n","* `classes` asigna clases de hoja de estilo en cascada (CSS).\n","* `render_links` especifica si convertir las URL en enlaces HTML.\n","* `table_id` asigna la identificación de CSS a la etiqueta de la tabla.\n","* `escape` decide si convertir los caracteres `<`, `>` y `&` en cadenas compatibles con HTML.\n","\n","Utilice parámetros como estos para especificar diferentes aspectos de los archivos o cadenas resultantes.\n","\n","Puede crear un objeto DataFrame a partir de un archivo HTML adecuado usando `read_html()`, que devolverá una instancia de DataFrame o una lista de ellos:"],"metadata":{"id":"xuPr5QDme-ww"}},{"cell_type":"code","source":["df = pd.read_html('data.html', index_col=0, parse_dates=['IND'])"],"metadata":{"id":"VKUqcY5Zhkwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df #df[0]"],"metadata":{"id":"01OCxaSItBP3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esto es muy similar a lo que hizo al leer archivos CSV. También tiene parámetros que lo ayudan a trabajar con fechas, valores faltantes, precisión, codificación, analizadores HTML y más."],"metadata":{"id":"EROBNGtfe-uJ"}},{"cell_type":"markdown","source":["### __Archivos SQL__\n","\n","__Pandas IO tools__ también pueden leer y escribir bases de datos. En el siguiente ejemplo, escribiremos nuestros datos en una base de datos llamada _Paises_.\n","\n","Python tiene un controlador incorporado una librería para trabajar con el motor de base de datos __SQLite__. Necesitaremos un controlador (driver) para la base de datos."],"metadata":{"id":"4yZv2kqbhvvb"}},{"cell_type":"code","source":["import sqlite3"],"metadata":{"id":"taYnt45WdFDX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### sqlite3.connect( )\n","Mediante el método `connect()` podemos crear una BD o conectarnos a una ya existente. El método retorna un objeto de tipo `SQLite Connection`.\n","\n"],"metadata":{"id":"RMCA_qPx09kW"}},{"cell_type":"code","source":["connection = sqlite3.connect(\"data.db\")"],"metadata":{"id":"fFDjS0G98KRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -l data.db"],"metadata":{"id":"HJDy4eIj8bpo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["También es posible especificar que se creará una BD en RAM usando `\":memory:\"`."],"metadata":{"id":"8CKl4gm88Jp9"}},{"cell_type":"code","source":["connection2 = sqlite3.connect(\":memory:\")"],"metadata":{"id":"23j0ypk8076i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["connection2"],"metadata":{"id":"WNZbV-Zb2-Xg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `connection.cursor()`\n","Luego de crear la BD, crearemos un cursor.<br>\n","Un cursor se utiliza para ejecutar sentencias SQL y recuperar los resultados de dichas sentencias.<br>\n","El cursor se crea utilizando el objeto `SQLite Connection` del paso anterior."],"metadata":{"id":"UlNknjeb5hxw"}},{"cell_type":"code","source":["cursor = connection.cursor()\n","cursor"],"metadata":{"id":"X4i3zt5f51wI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora que tenemos configurada nuestra base de datos (en memoria), el siguiente paso es crear un objeto DataFrame. Usaremos el método `.to_sql()`.Es conveniente especificar los tipos de datos a utilizar."],"metadata":{"id":"Xh3PtivH19PB"}},{"cell_type":"code","source":["dtypes = {'POB': 'float64', 'AREA': 'float64', 'PGB': 'float64',\n","          'IND': 'datetime64'}\n","df = pd.DataFrame(data=data).T.astype(dtype=dtypes)\n","df.dtypes"],"metadata":{"id":"4peRd7i72O1t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`.astype()` es un método muy conveniente que puede usar para establecer varios tipos de datos a la vez.\n","\n","Una vez que haya creado su DataFrame, puede guardarlo en la base de datos con `.to_sql()`:"],"metadata":{"id":"5ejIhMo819MI"}},{"cell_type":"code","source":["df.to_sql('paises', con=connection, index_label='ID') # if_exists='replace'"],"metadata":{"id":"2j6z643U2ry0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El parámetro `connection` se usa para especificar la conexión de la base de datos o el motor que desea usar. El parámetro opcional `index_label` especifica cómo llamar a la columna de la base de datos con las etiquetas de fila. A menudo verá que toma el valor _ID_, _Id_ o _id_.\n","\n","Debería obtener la base de datos _data.sql_ con una sola tabla _paises_ que se vea así:"],"metadata":{"id":"balo765q19Jx"}},{"cell_type":"code","source":["cursor.execute(\"\"\"SELECT *\n","                  FROM paises\n","              \"\"\")\n","for rec in cursor.fetchall():\n","    print(rec)\n","connection.commit()"],"metadata":{"id":"jZU8Rl_Y3S2_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La primera columna contiene las etiquetas de las filas. Para omitir escribirlos en la base de datos, pase `index=False` a `.to_sql()`. Las otras columnas corresponden a las columnas del DataFrame.\n","\n","Hay algunos parámetros opcionales más. Por ejemplo, puede usar `schema` para especificar el esquema de la base de datos y `dtype` para determinar los tipos de las columnas de la base de datos. También puede usar `if_exists`, que dice qué hacer si ya existe una tabla con el mismo nombre y ruta:\n","\n","* `if_exists='fail'` genera un `ValueError` y es el predeterminado.\n","* `if_exists='replace'` descarta la tabla e inserta nuevos valores.\n","* `if_exists='append'` inserta nuevos valores en la tabla.\n","\n","Puede cargar los datos de la base de datos con `read_sql()`:"],"metadata":{"id":"hsc8_be918-m"}},{"cell_type":"code","source":["df = pd.read_sql('SELECT * FROM paises', con=connection, index_col='ID')\n","df"],"metadata":{"id":"BAY0TiLI7ME8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El parámetro `index_col` especifica el nombre de la columna con las etiquetas de fila. Tenga en cuenta que esto inserta una fila adicional después del encabezado que comienza con ID. Puede corregir este comportamiento con la siguiente línea de código:"],"metadata":{"id":"cp6mgXxb_qlz"}},{"cell_type":"code","source":["df.index.name = None\n","df"],"metadata":{"id":"y6LwghVb_xBS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora tiene el mismo objeto DataFrame que antes.\n","\n","Tenga en cuenta que el continente (_'CONT'_) de Rusia ahora es `None` en lugar de `NaN`. Si desea completar los valores faltantes con `NaN`, puede usar `.fillna()`:\n","\n","```python\n","df.fillna(value=float('nan'), inplace=True)\n","```\n","`.fillna()` reemplaza todos los valores faltantes con lo que le pases al valor; en este caso con `NaN`.\n","\n","También tenga en cuenta que __no tuvo que pasar__ `parse_dates=['IND']` a `read_sql()`. Eso es porque su base de datos pudo detectar que la última columna contiene fechas. Sin embargo, puede pasar `parse_dates` si lo desea. Obtendrás los mismos resultados.\n","\n","Hay otras funciones que puede usar para leer bases de datos, como `read_sql_table()` y `read_sql_query()`. Experimentes con ellas!"],"metadata":{"id":"txTY-W2S_qi3"}},{"cell_type":"code","source":["# Buena práctica; no olvides cerrar la conexión\n","connection.close()\n","connection2.close()"],"metadata":{"id":"jj1zfQvyBCjl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### __Archivos Pickle__\n","__Pickling__ es el acto de convertir objetos de Python en flujos de bytes. __Unpickling__ es el proceso inverso. Los archivos _pickle_ de Python son archivos binarios que mantienen los datos, su estructura, los tipos y la jerarquía de los objetos de Python. Su gran ventaja es que son muy eficientes en el uso de espacio y en la velocidad para escribirlos y leerlos; en estas funciones, superan fácilmente a los otros tipos de archivo que hemos visto. Su desventaja es que no pueden ser visualizados directamente en el disco. Suelen tener la extensión `.pickle` o `.pkl`.\n","\n","Puede guardar su DataFrame en un archivo pickle con el método `.to_pickle()`:"],"metadata":{"id":"DZhRYByj_qgh"}},{"cell_type":"code","source":["dtypes = {'POB': 'float64', 'AREA': 'float64', 'PGB': 'float64',\n","          'IND': 'datetime64'}\n","df = pd.DataFrame(data=data).T.astype(dtype=dtypes)\n","df.to_pickle('data.pickle')"],"metadata":{"id":"ycm0FkN7CSjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -l data.pickle"],"metadata":{"id":"iBQJipsKCSYb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Al igual que hizo con las bases de datos, puede ser conveniente especificar primero los tipos de datos. También puede pasar un valor entero al parámetro opcional `protocol`, que especifica el protocolo del pickler.\n","\n","Puede obtener los datos de un archivo pickle con `read_pickle()`:"],"metadata":{"id":"O3Crtf5QVA32"}},{"cell_type":"code","source":["%%timeit\n","df = pd.read_pickle('data.pickle')"],"metadata":{"id":"34IFofZBDNJD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`read_pickle()` devuelve el DataFrame con los datos y sus tipos almacenados. También puede consultar los tipos de datos:"],"metadata":{"id":"6wrVSk0oEL4B"}},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"HI2OC0IeEeXy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["__Importante__: Hay que tener en cuenta que hay que tener cuidado de cargar archivos _pickle_ de fuentes no confiables. Cuando lee un archivp _pickle_ de una fuente no confiable, podría ejecutar código arbitrario en su máquina, o generar alguna vulnerabilidad en su computadora."],"metadata":{"id":"je2oK2J7Efwr"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?export=view&id=1Igtn9UXg6NGeRWsqh4hefQUjV0hmzlBv\" width=\"50\" align=\"left\" title=\"Runa-perth\">\n","<br clear=\"left\">"],"metadata":{"id":"kts1BIdCv1l9"}}]}